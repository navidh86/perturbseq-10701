{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navidh86/perturbseq-10701/blob/master/test_dataset_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "64cefba8",
      "metadata": {
        "id": "64cefba8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "81027b47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81027b47",
        "outputId": "7605ed31-6399-49f2-bbdc-6e3aaa180e31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'perturbseq-10701'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 65 (delta 18), reused 31 (delta 5), pack-reused 9 (from 1)\u001b[K\n",
            "Receiving objects: 100% (65/65), 91.05 MiB | 36.58 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/perturbseq-10701\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastparquet) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n"
          ]
        }
      ],
      "source": [
        "# ONLY FOR COLAB\n",
        "!git clone https://github.com/navidh86/perturbseq-10701.git\n",
        "%cd ./perturbseq-10701\n",
        "!pip install fastparquet tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & Config\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddy4uZQ39Bk2",
        "outputId": "2369d277-4195-4ecf-b31a-eff129884a38"
      },
      "id": "ddy4uZQ39Bk2",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader import\n",
        "\n",
        "from reference_data_alternate import (\n",
        "    PairPerturbSeqDataset,\n",
        "    perturbseq_collate,\n",
        "    get_dataloader\n",
        ")\n"
      ],
      "metadata": {
        "id": "teVdRnvn9Mkf"
      },
      "id": "teVdRnvn9Mkf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load loaders\n",
        "\n",
        "train_loader = get_dataloader(type=\"train\", batch_size=32)\n",
        "test_loader  = get_dataloader(type=\"test\", batch_size=32)\n"
      ],
      "metadata": {
        "id": "rv99Njqj9N3d"
      },
      "id": "rv99Njqj9N3d",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "\n",
        "batch_x, batch_y = next(iter(train_loader))\n",
        "print(batch_x[0])\n",
        "print(batch_y[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJGTRHq29QD-",
        "outputId": "4c75010a-1834-4a56-835d-daeaf9f4ccdf"
      },
      "id": "sJGTRHq29QD-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tf_name': 'MYBL1', 'tf_seq': 'GCAGAACTGCTAGCTGCGGGGGAGAGGGCAGGGGTCGGGCGCCTGTGGCGGAGCCGGGCTGGGGCCAGGGCAGGGAGGCTGACAAGCGGCGGGAGAAGCCGGCGGAGGGCGGGATCGCGCCTCCTGACATGTTGGGGGTATCCCTGGCCGGGCCGGGCCGGGGCTAAGAGCGGCGCTGCGGGCCGGGGTCGGGGTCGGGTCGCGGTCCGCCCCCGCTGTCCCTCCGTCCTGCCCTGTCGAGGACGTGCGTTCCGCACTCGGCCGCCTCCAGAGGGAGCGAGGGAAGCGGCTAGAGGATCGGGGAGAAGGAGCATTCGCCGGAGGCTGGAGGAGGCTGACCCGCGTCCCCGCCCAGCCTGCTCCTATGCGGTACTTGAAGGATGGCGAAGAGGTCGCGCAGTGAGGATGAGGATGATGACCTTCAGTATGCCGATCATGATTATGAAGTACCACAACAAAAAGGACTGAAGAAACTCTGGAACAGAGTAAAATGGACAAGGGACGAGGATGATAAATTAAAGAAGTTGGTTGAACAACATGGAACTGATGATTGGACTCTAATTGCTAGTCATCTTCAAAATCGCTCTGATTTTCAGTGCCAGCATCGATGGCAGAAAGTTTTAAATCCTGAATTGATAAAGGGTCCTTGGACTAAAGAAGAAGATCAGAGGGTTATTGAATTAGTTCAGAAATATGGGCCAAAAAGATGGTCTTTAATTGCAAAACATTTAAAAGGAAGAATAGGCAAGCAGTGTAGAGAAAGATGGCATAATCATCTGAATCCTGAGGTAAAGAAATCTTCCTGGACAGAAGAGGAGGACAGGATCATCTATGAAGCACATAAGCGGTTGGGAAATCGTTGGGCAGAAATTGCCAAACTACTTCCAGGAAGGACTGATAATTCTATCAAAAATCATTGGAATTCTACTATGCGAAGAAAAGTGGAACAGGAGGGCTATTTACAAGATGGAATAAAATCAGAACGATCTTCATCTAAACTTCAACACAAACCTTGTGCAGCTATGGATCATATGCAAACCCAGAATCAGTTTTACATACCTGTTCAGATCCCTGGGTATCAGTATGTGTCACCTGAAGGCAATTGTATAGAACATGTTCAGCCTACTTCTGCCTTTATTCAGCAACCCTTCATTGATGAAGATCCTGATAAGGAAAAGAAAATAAAGGAACTTGAGATGCTTCTTATGTCAGCTGAGAATGAAGTTAGAAGAAAGCGAATTCCATCACAGCCTGGAAGTTTTTCTAGCTGGTCTGGTAGTTTCCTCATGGATGATAACATGTCTAATACTCTAAATAGCCTTGACGAGCACACTAGTGAGTTTTACAGTATGGATGAAAATCAGCCTGTGTCTGCTCAGCAGAATTCACCCACAAAGTTCCTGGCCGTGGAGGCAAACGCTGTGTTATCCTCTTTGCAGACCATCCCAGAATTTGCAGAGACTCTAGAACTTATTGAATCTTTTAATTTATTGCAGGATCCTGTAGCATGGAGTGACGTTACCAGTTTTGATATTTCTGATGCTGCTGCTTCTCCTATCAAATCCACCCCAGTTAAATTAATGAGAATTCAGCACAATGAAGGAGCCATGGAATGCCAATTTAACGTCAGTCTTGTACTTGAAGGGAAAAAAAACACTTGTAATGGTGGCAACAGTGAAGCTGTTCCTTTAACATCCCCAAATATAGCCAAGTTTAGCACTCCACCAGCCATCCTCAGAAAGAAGAGAAAAATGCGAGTGGGTCATTCCCCAGGCAGCGAACTTAGGGATGGCTCATTGAACGATGGTGGTAATATGGCGCTAAAACATACACCACTGAAAACACTACCATTTTCTCCTTCACAGTTTTTCAACACATGTCCTGGTAATGAACAACTTAATATAGAAAATCCTTCATTTACATCAACCCCTATTTGTGGGCAGAAAGCTCTCATTACAACTCCTCTTCATAAGGAAACAACTCCCAAAGATCAAAAGGAAAATGTAGGGTTTAGAACACCTACTATTAGAAGATCTATACTGGGTACCACACCAAGAACTCCTACTCCTTTTAAGAATGCGCTTGCTGCTCAGGAGAAAAAATATGGACCTCTTAAAATTGTGTCCCAGCCACTTGCTTTCTTGGAAGAAGATATTCGGGAAGTTTTAAAAGAAGAAACTGGAACAGACCTATTCCTCAAAGAGGAAGATGAACCTGCTTACAAAAGCTGCAAACAAGAGAATACCGCTTCTGGGAAGAAAGTCAGAAAATCACTAGTCTTAGATAATTGGGAAAAAGAAGAATCAGGCACTCAACTGTTGACTGAAGACATTTCAGACATGCAGTCAGAAAATAGATTTACTACATCCTTATTAATGATACCATTATTGGAAATACATGACAATAGGTGCAACTTGATTCCTGAAAAACAAGATATAAATTCAACCAACAAAACATATACACTTACTAAAAAGAAACCAAACCCTAACACTTCCAAAGTTGTCAAATTGGAAAAGAATCTTCAGTCAAATTGTGAATGGGAAACAGTGGTTTATGGGAAGACAGAAGACCAACTTATTATGACTGAACAAGCAAGAAGATATCTGAGTACTTACACAGCTACCAGTAGTACTTCAAGAGCTCTCATACTGTAATTGTTATTAAAATTGATGAAATGCCCCACTCCCTTACTGCAGTCTCTACTAAATTAGGTTGCAGTGAAATTTTTCTCAATTAGTTGTTTTTAAAGTTGTAAGATAGCCCTTTTAATACAGCATCTTTTTTCTATTCTATATAGTAGGCAGAAAGCTAGTAAGTCACTTAAGGGGTAGATAGTTTCATAGTTTATTTTTTAAGAGATGAGATTTTTAAAAATTGTTTTTAAAGAACAAGATGGGAAAATAATAGAATGTTCATGGATTTCTAAAAGTAAATTCTCATATATTTTCTTCACAAGATATATGTTGCTACTCTCTTGATGCTGCAGTTTTGTTATAGATAGGTGTATGAGTATATATGATTTCTGAAATTAGTCTATGTATGGAAAGCACACATGATTTTATGAAGTACTTTTGCCCATGTGCTGATTTACTTAGGCTACCATTTACAAAGAAACACATTGAAAAGGAATTTAAAGGAAGGATAGAAAGTTGCACTACTAATTTTTTGTTTTTTTTTTCAGAAGCAGTAAAATTAACTACAGTGTTAAATGTATTTATTTGAGCATAGTACTGAAAACAAAAAGCATTCAAAAAAGAGTTTTTTCTTTATTAGTAAATAGTATTTTCTTAATCTCAGAGGAGCTGAGAGTTTTGTTGAATGTATTGTACAGTATGTAGGAGCAGGAGAACTTTGTAAATTGGAAAGAAGTCTGTTTTTATAATTTATTTTTATTTTTAAAGCTTAAATGTAGATATTTATACGTATACAGGGTGCCTAGAAGCCAATGTTGTTTCCTGTTATTACAGCTAACACAGTAAAGAATAATTTTGACTTTAAGTATGAAACAGTAGTAAGTTATAGCTGCAAAGAATACAATATCTATACTGTATGTCACATCTACCTAAATGTTGCACTATGCCCTTTAAATCATGCTGGTTATAAAGTAGTTCTAAAAATGTACTAAATAATAATTTAATATTTTCTTTTTAAATTATATCGGGGGTGGTCATATACATTAATCTGGTGATTTGTATATGTGTTTGAAATTTTTGCATTTTGTTTAAAAAATAATATGGTACCTTGGTCCCTAAAAACAGTCTGCACTTAGAAGTTTATATTTACTCAGTGTTTCAGAAGTGGAGAACATTATCTTTTATTTATAAAAATATTTTGTCCTTTTTTAAATGTTTTGTGTTTCTCTACAGGTTACAACAGTTGCTTCAGTTGCCTGTTTTAGGTGTTTGCACTTATTTTATTTCTTCTTGAAAGAATTTTTATTTGCTTTTGTGGTAGAGATTATATGTAATTTTTTTTCAGTCATATAATGGTGTGCTGTCAACTTAAACACTGACAGGTAAATAGAATTGTACACTGTAGTTTGAATTATTTATAATTGACACACTCTCTCCCTCTCCACTCCTGAAGTATGCTGCTATAGAAAATAGCAGAATCGGCTTGCTGCTACGAGAGAAGGAAAGAGCGACCACCACTTGCACTGTGTGAAAAGATAAAAAACAAATGATGGCAAGTTCTCAAGTTAACTAAATGGAATCAACCATTACCAGGCAAATTCTTGCAAATACCAAAATACTACTATGCCTTATAAAACAAAATGAAAGCAGGTTAAGATTTTCTGCTCTGTTTGTATGTTAATAGAAATGGAAATACTAAGTATTTTAATGCTTAGCTCTTGAACAGTAGACCTAAAAGGGTTTTAAGCTATTTAAATCTACTTGCTAGTTTTTGCATATTTTATATATATATATATTTATATATATATATAGTGAGAAGTGAAGAAAATGTATGGTACTAAGATTATGCCTTATTGATAAATAGATAAACCAATTTGAATCCTCTTAGCATGTTTAAGTATGTTGATTGCTTTCTAATTAATGAACTTCTCACAGAAATTTCACTTAGTGAAACCAATGATTGTAGCAAACTCATACTGGATCATTTCAGTTACCTTGAACTAATAGCACATAATGGTTTTTTGTTGTTGTTGTTTTTAATGTAGCCCTTACCTGGATATACATAGTCTGCAATCACCAAAGTATAATATCTTGTAAGGCTATATTTTTTAAAGCATATTTTTTCTTGAGCATTAAATTATCCTAAATGGTAATATATTGTGGATAAGTCTGGGCTTATTGGACATAATACATATTTGGGTTGGTACTGGTTGAATCCTTCAGTTAACTGCTTTGTTGCTTTTTGCAAGATTTTTTATCTTAAACATGTCAGGCATCTTAAGTCACCTTTATACTGTTTTGTTCCTCTGAGTTTCTTTCAGTATGTTATACAAATGCCAGACATAACATGTAGCAGCCATACTTGCATGGAAACTGACTACACATACATAATACTGCATTTTATTGTAAGGTTTTCACATTAATACAGCAATTACCCTGACTAAATTGAGTTTTGTGATATATGGAAAACTTCATTGTAAGAGAATCTTGCATACAATGTTGACATATTAACATCCAAAATAAAGCATCTGTGTACAAGCTGA', 'gene_name': 'PWWP3A', 'gene_seq': 'ggttcaagagattttcttgcctcagcctcccaaatagctgggattacaggtgcacactaccacgctcagccaatttttgtatttttagtagcgatgggggtttctctatattggccaggctggtctcgaactcctgacctcaggcgatatgtctgccttgacctcccaaagtgctgggattacaggcctgagccaccgccaGCTCAGATTTAACGTGAGAGGATATCAGAGACATAGTTCTTGCCAACCACCCACAGACCAccacccccattttatagacaaactGAGACGGCTGAGCAAGGTGGATcctacctgtgatcccagcactttggggagccgaggtgggaggatcacttgagcccaaaaggtcgaaaccagcctggccagcatagcaagaccctctctctacaaaaaataaaaatcttagccagccatggtggtgcgcactgtggtcccagctactccggaggctaaggtggaaggatcatttgagcctgggaggttgaggctgcagtgagctatgactgggccgctgcactccagcctgggccacagagccaaacTTCGactcaaaaatgtaaataaaaataaaaaacaagtgaaaGGTGAAcattctcaacttgataaaggaaaaaaaatcagtcgcTGAGGTTGCTGGGATCGACCGAAGACACAAACCTTCTATTCCCGCAAAtgtgagaaggaaaaagaagttaGAGCCGGCTTTGCTGTCGCCCCTTCCCCTTGAAGAGTCGGGGCCAGTGCGTGACGAATGCTGCTGtaagtcttttaattttttccttttttgagacgaagtcccactctgttgcccaggctggagtgcagtggcgcgatctccccttactgcaagttccgcctcccgggttcaagcgattctcctgcctcagcctcctgaatagttgggattacaggcatcgccaccacgcccggctaatttttctatttgtagtaaagacggggtttcaccatgttggcaatgctggtctcgatctcctgacctcatgtgatctgcccgcctcggcctcctgctgggattacaggagtgagcctgtatcttttttatagagatggggtctcgccatgttgcccaggctggtctccaatccTTGGGCTTAAAGGATCTGCCAATTCGGCCTCCTTTGCTTTTAAAGAACTGTGGGGGCTggcgaggtggctcaggcctgtaatcccaatactttgggaggccgaggcaggccgatcacctgaggtcaggagcttgagagcaGCCTGATCAACATTTAgtattctctactaaaaatacaaaaattagccgggtggggtggcgcgcacctgtaatcccagcaggaggaggctgcagtgagctgagctcgcgccactgcactccagcctgggtgacagagcgagactccgtctgaaaaaaaatcaaaaaccgcTCAGGGAAAGGCCTGACACTGATGGAGCGACCGCTCCGGGGCTCCCGCCACCCGCGGCTGTTTCCGGTGCCCCCCGGGGTCTTGGGACCCTCCCAAGGTGGGTCCTGCTCTAGTTCAGAAGCTTATGACGCCTTTGCGGGGATGCCTGGCTTTGGGATCGGTTGGGATCTGCTGGAATTGGGTCCGTGGCGCGCAGCTCCCGGGCTGGGAGGTGCCGTAGGACCTGGAAGATTCTCGAAAGTTCTGGAAGGTTCTCTCAGGGATCGCCGCGGGCGGGGGAGCCTGTTTTCCCACCGAGACCCGCGAGGGCGGTGTCCGGGGTCTGACTGCAGGACAAAGGGCCGGGAGCGCGGGAGGGCGGCGCCCGGGAGCGGCCACACATGCCCCGCCAACCGGTCTCCTCAGGCAGCACTCCCGGGAAAAAGGGGTAGACGCGCGGCGGAAGGGGCGGGGCCGGCGCGCGGCCGTGGACGCCGGAGAGGGCGAGGCCGGCGCTCCTTGGGAGCGCGCGCGTCCCATTGGGCAGCGGGCGGAAGGGGGCGGAGCTTGGCGCCGCCGCGAGGCaagccccgcccccggccccgcggggagcggcggcggcggcggcggcggcggtggcggagGCGGTGAGCGCGGGCGGCGCGGACGGCAGCGGTTGGCGGGCGGGTCCTCCGCTGTTGCGGCCGCTGCGGCCTCCTTGCCCGGGCTTGGGGCGCCGCGCTGGGGAAAGCCGGGGGCCCGGTGAGCCCGCGGGATGCGTCCCCTCGGTTCCGCCGGGCGGGGCTGAGGCGAGGAGGCCGGgcctggggggagggggggccCCGGCCTAGAGACTCCTCCGGGAGCGCCCGGTCCCTACCGCCGTGGGTCCCCCACTCTGCCCGGACCCCCTTTTCCGCCCCTGGCGCCGTGGGCCCCTCACTTTGCCTGGACTCCTTTTCCCGTCCCTGCCGCCCGGACCCCATCTCTTGCTTGGACCCGCTCCCCCATCCTTGCTGCCTGGACCCCTATCTCCTTCCCTGGATCCCCCTCACGTCTGCCGTGAACCCCATCTCTTGCCTGGACCCCCATCTGCTTCCCTGGATTCCCCACCCCCAACCGTGAAATCCCCCATCCCTGCCACCTGGACCCTCCGCTCCACCTCCTCCGTGAGCCCTCGTTCTTGCTCCCTGAGCCCCCCCGCTTCTGCTGTGACCCCCTTCTCTGTTGCCTGAATCCCCCGTTCCTGCAAGCCGCAACCCTTCCTCCGCCATGAAATCTTGTCCCTGCTGCCTGGACCCCtacttctgctgctgctgtgatCCCCTCTCTTGCTGGAAACGCCACCCCTACCTCTGCTGGGAACCTCCTCTTCCCTGCTGCGGGGACGCCCCCCTCCGTTGTTGCTaaattccacccccacccccaaacctccttttcatttctgtcaaCAGCCAAGCCAGTCCTTCCCATTGATGCTGTGAACGGTCTGCAGCTGTCCCCGTTCTTTCAGGGACATGGCAGCCAAAAGAGCAGTCGTTTTTCCGctcttatttttgtgtgtgtgctgtggtcAACTGTTAACTCCCCAAATTGGGGAGGGTTGTGAGCTTTGATTGTGTAAAATGCCTCTCCTGCCGAGGTCGGAGGCAGGTCTTCCGCACGGAGATGATTTATTCAGGAGCCTTTTAAAACTGATCTAGATAGAACCTTTGGGAGGGACtgtgctgtattttatttatgaaaaaatgcaGGCGCCTCCCTGGATACCGAGCCCCGTCGTTTCTGTTTGTCAGTCTGCTTTTTGGCATTGAGCATCTCAATGCAAGATTGTGGAATTAAACCATCTACTTGAGGCTAAGTCGAGCTAACCTTTGCCCCTGAGGGCTGTGTCTGCGTTAACATCGCCAGCAAACAGTTGTATAAACCACCGTGCAAATTTCGTTCCAGGACACATTGGCGTGAGACCTGGGAGTACGTTGTGCCAAATCATTGCCACTTGCCACATGAGTGTAAATGATGGCGGATGCCAAGTATGTCCTCTGCCGATGGGAAAAGCGATTATGGCCTGCGAAGGTGACAGCCATTATTCTGTAACTTCAGGACTTAGAAATGACTTTCGGGTGACAAGTAAAATCTTGATCAGGAGATACCTAGGATTTGCTTCAGTGAAATAATTGAGCCAGAACACGGTTGGCACTGATTCTCGTTCCCCATTTAATGGGGTTTTGGTCTAGTGCTTCCAAGGTTACACTtccagaaatgtcttttttttttcacactaaaaaaaaaaaaagaatcagctgTAAAAAGGCATGTAAGGCTGTAACTCAAGGAAAGATCTGGCAAGCAGCCCTGTGATAGTAAATTATGGTCGTGTTCAGGGAATGCTTTCCAGCAATTCAGTAGACAGTGCTCAGCTGCAATGCAAAAGCCCAGGTCCTTGTCTTTGTCTGCCACTGGCctctcatgcctcagtttccccatctgtgaaacaaTGGGGATTGGACCAAATATCTGAAATCCCATGGTTATAGGCCTTCAGGATTACCTGCTGCATTTGTGCTAAAGTTTGCCACTGTTTC'}\n",
            "tensor(0.1703)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF & Gene Name Vocabularies\n",
        "\n",
        "tf_seqs = pickle.load(open(\"tf_sequences.pkl\", \"rb\"))\n",
        "gene_seqs = pickle.load(open(\"gene_sequences_4000bp.pkl\", \"rb\"))\n",
        "\n",
        "tf_to_id = {name: i for i, name in enumerate(tf_seqs.keys())}\n",
        "gene_to_id = {name: i for i, name in enumerate(gene_seqs.keys())}\n",
        "\n",
        "num_tfs = len(tf_to_id)\n",
        "num_genes = len(gene_to_id)\n",
        "\n",
        "print(num_tfs, \"TFs,\", num_genes, \"genes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0Pkpu-u9SXW",
        "outputId": "34fb7644-e628-4274-e9b1-a7ae2d602fab"
      },
      "id": "-0Pkpu-u9SXW",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223 TFs, 5307 genes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Dataset Statistic\n",
        "\n",
        "train_dataset = PairPerturbSeqDataset(type=\"train\")\n",
        "\n",
        "all_y = []\n",
        "loader = DataLoader(train_dataset, batch_size=512, collate_fn=perturbseq_collate)\n",
        "\n",
        "for _, y in loader:\n",
        "    all_y.extend(y.numpy())\n",
        "\n",
        "all_y = np.array(all_y)\n",
        "mu, sigma = all_y.mean(), all_y.std()\n",
        "\n",
        "print(\"Mean:\", mu, \"Std:\", sigma)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUP5U89f9UcG",
        "outputId": "4fad3879-cb37-483a-f4b0-fd64bf7b6b05"
      },
      "id": "pUP5U89f9UcG",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: -0.022736955 Std: 0.15207928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted mse loss define\n",
        "def weighted_mse_loss(pred, target, mu, sigma, alpha=3.0, threshold=1.0):\n",
        "    z = (target - mu) / sigma\n",
        "    weights = torch.where(torch.abs(z) > threshold,\n",
        "                          torch.tensor(alpha, device=target.device),\n",
        "                          torch.tensor(1.0, device=target.device))\n",
        "    mse = (pred - target)**2\n",
        "    return (weights * mse).sum() / weights.sum()\n"
      ],
      "metadata": {
        "id": "5vaMzhiU-oRy"
      },
      "id": "5vaMzhiU-oRy",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DNA Tokenizer\n",
        "\n",
        "dna_map = {\"A\":0, \"C\":1, \"G\":2, \"T\":3, \"N\":0}\n",
        "\n",
        "def encode_seq(seq):\n",
        "    return torch.tensor([dna_map.get(ch, 0) for ch in seq], dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "OQBQOZf39V31"
      },
      "id": "OQBQOZf39V31",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF+Gene Identity Baseline\n",
        "\n",
        "class TFGeneIDModel(nn.Module):\n",
        "    def __init__(self, num_tfs, num_genes, emb_dim=32):\n",
        "        super().__init__()\n",
        "        self.tf_emb = nn.Embedding(num_tfs, emb_dim)\n",
        "        self.gene_emb = nn.Embedding(num_genes, emb_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2*emb_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, tf_ids, gene_ids):\n",
        "        t = self.tf_emb(tf_ids)\n",
        "        g = self.gene_emb(gene_ids)\n",
        "        h = torch.cat([t, g], dim=-1)\n",
        "        return self.mlp(h).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "ag6_R_5P9_zG"
      },
      "id": "ag6_R_5P9_zG",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence Bi-Encoder (Simple Prototype)\n",
        "\n",
        "class SimpleSeqEncoder(nn.Module):\n",
        "    def __init__(self, vocab=4, emb_dim=16, hidden=64):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab, emb_dim)\n",
        "        self.conv = nn.Conv1d(emb_dim, hidden, kernel_size=7, padding=3)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "    def forward(self, seq_batch):\n",
        "        padded = nn.utils.rnn.pad_sequence(seq_batch, batch_first=True)\n",
        "        x = self.emb(padded)                     # (B, L, emb)\n",
        "        x = x.transpose(1, 2)                    # (B, emb, L)\n",
        "        x = torch.relu(self.conv(x))            # (B, hidden, L)\n",
        "        x = self.pool(x).squeeze(-1)            # (B, hidden)\n",
        "        return x\n",
        "\n",
        "class SeqBiEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = SimpleSeqEncoder()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, tf_seqs, gene_seqs):\n",
        "        tf_h = self.encoder(tf_seqs)\n",
        "        gene_h = self.encoder(gene_seqs)\n",
        "        h = torch.cat([tf_h, gene_h], dim=-1)\n",
        "        return self.mlp(h).squeeze(-1)\n",
        "\n"
      ],
      "metadata": {
        "id": "oloJOYks-EaW"
      },
      "id": "oloJOYks-EaW",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop (Unified for ID & Seq Models)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, mu, sigma,\n",
        "                    use_sequences=True, device=\"cuda\"):\n",
        "    model.train()\n",
        "    total_loss, N = 0.0, 0\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # ----- Prepare ID inputs -----\n",
        "        tf_ids = torch.tensor([tf_to_id[x[\"tf_name\"]] for x in batch_x]).long().to(device)\n",
        "        gene_ids = torch.tensor([gene_to_id[x[\"gene_name\"]] for x in batch_x]).long().to(device)\n",
        "\n",
        "        # ----- Prepare sequences -----\n",
        "        if use_sequences:\n",
        "            tf_seqs = [encode_seq(x[\"tf_seq\"]).to(device) for x in batch_x]\n",
        "            gene_seqs = [encode_seq(x[\"gene_seq\"]).to(device) for x in batch_x]\n",
        "        else:\n",
        "            tf_seqs, gene_seqs = None, None\n",
        "\n",
        "        # ----- Forward pass -----\n",
        "        if use_sequences:\n",
        "            preds = model(tf_seqs, gene_seqs)\n",
        "        else:\n",
        "            preds = model(tf_ids, gene_ids)\n",
        "\n",
        "        loss = weighted_mse_loss(preds, batch_y, mu, sigma)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        N += len(batch_y)\n",
        "\n",
        "    return total_loss / N\n"
      ],
      "metadata": {
        "id": "PNcB6ObY-KJm"
      },
      "id": "PNcB6ObY-KJm",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "\n",
        "def evaluate(model, loader, mu, sigma, use_sequences=True, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    preds_all, y_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in loader:\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            tf_ids = torch.tensor([tf_to_id[x[\"tf_name\"]] for x in batch_x]).long().to(device)\n",
        "            gene_ids = torch.tensor([gene_to_id[x[\"gene_name\"]] for x in batch_x]).long().to(device)\n",
        "\n",
        "            if use_sequences:\n",
        "                tf_seqs = [encode_seq(x[\"tf_seq\"]).to(device) for x in batch_x]\n",
        "                gene_seqs = [encode_seq(x[\"gene_seq\"]).to(device) for x in batch_x]\n",
        "                preds = model(tf_seqs, gene_seqs)\n",
        "            else:\n",
        "                preds = model(tf_ids, gene_ids)\n",
        "\n",
        "            preds_all.append(preds.cpu())\n",
        "            y_all.append(batch_y.cpu())\n",
        "\n",
        "    preds_all = torch.cat(preds_all)\n",
        "    y_all = torch.cat(y_all)\n",
        "\n",
        "    mse = ((preds_all - y_all)**2).mean().item()\n",
        "    corr = torch.corrcoef(torch.stack([preds_all, y_all]))[0,1].item()\n",
        "\n",
        "    # Large-effect subset\n",
        "    z = (y_all - mu) / sigma\n",
        "    mask = torch.abs(z) > 1.0\n",
        "\n",
        "    if mask.sum() > 0:\n",
        "        mse_big = ((preds_all[mask] - y_all[mask])**2).mean().item()\n",
        "        corr_big = torch.corrcoef(torch.stack([preds_all[mask], y_all[mask]]))[0,1].item()\n",
        "    else:\n",
        "        mse_big, corr_big = None, None\n",
        "\n",
        "    return mse, corr, mse_big, corr_big\n"
      ],
      "metadata": {
        "id": "kETAmY1D-QPt"
      },
      "id": "kETAmY1D-QPt",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ID baseline\n",
        "\n",
        "model_id = TFGeneIDModel(num_tfs, num_genes).to(device)\n",
        "optimizer = optim.Adam(model_id.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(5):\n",
        "    loss = train_one_epoch(model_id, train_loader, optimizer, mu, sigma,\n",
        "                           use_sequences=False)\n",
        "    print(f\"[ID Baseline] Epoch {epoch} | Loss={loss:.4f}\")\n",
        "\n",
        "mse, corr, big_mse, big_corr = evaluate(model_id, test_loader, mu, sigma,\n",
        "                                        use_sequences=False)\n",
        "print(\"Test: MSE =\", mse, \"Corr =\", corr)\n",
        "print(\"Large-effect: MSE =\", big_mse, \"Corr =\", big_corr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU3umWhu-XGo",
        "outputId": "a4d39107-bc04-4856-de75-8a568498d700"
      },
      "id": "ZU3umWhu-XGo",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ID Baseline] Epoch 0 | Loss=0.0438\n",
            "[ID Baseline] Epoch 1 | Loss=0.0405\n",
            "[ID Baseline] Epoch 2 | Loss=0.0382\n",
            "[ID Baseline] Epoch 3 | Loss=0.0377\n",
            "[ID Baseline] Epoch 4 | Loss=0.0372\n",
            "Test: MSE = 0.019195543602108955 Corr = 0.33441659808158875\n",
            "Large-effect: MSE = 0.07673805952072144 Corr = 0.4397140443325043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Seq-Bi-encoder\n",
        "\n",
        "model_seq = SeqBiEncoder().to(device)\n",
        "optimizer = optim.Adam(model_seq.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(5):\n",
        "    loss = train_one_epoch(model_seq, train_loader, optimizer, mu, sigma,\n",
        "                           use_sequences=True)\n",
        "    print(f\"[Seq Bi-Encoder] Epoch {epoch} | Loss={loss:.4f}\")\n",
        "\n",
        "mse, corr, big_mse, big_corr = evaluate(model_seq, test_loader, mu, sigma,\n",
        "                                        use_sequences=True)\n",
        "print(\"Test: MSE =\", mse, \"Corr =\", corr)\n",
        "print(\"Large-effect: MSE =\", big_mse, \"Corr =\", big_corr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe669vNI-Z3V",
        "outputId": "05117af0-2000-4cc8-fc91-8b6bbf3ccd65"
      },
      "id": "xe669vNI-Z3V",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seq Bi-Encoder] Epoch 0 | Loss=0.0442\n",
            "[Seq Bi-Encoder] Epoch 1 | Loss=0.0432\n",
            "[Seq Bi-Encoder] Epoch 2 | Loss=0.0431\n",
            "[Seq Bi-Encoder] Epoch 3 | Loss=0.0438\n",
            "[Seq Bi-Encoder] Epoch 4 | Loss=0.0437\n",
            "Test: MSE = 0.020954959094524384 Corr = 0.069491446018219\n",
            "Large-effect: MSE = 0.093931645154953 Corr = 0.1222829595208168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UrULMtn7-xbv"
      },
      "id": "UrULMtn7-xbv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}