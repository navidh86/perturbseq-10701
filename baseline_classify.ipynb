{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and device\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data.reference_data_classification import get_dataloader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders (point to data/ paths explicitly)\n",
    "train_loader = get_dataloader(\n",
    "    parquet_path='data/tf_gene_expression_labeled.parquet',\n",
    "    tf_sequences_path='data/tf_sequences.pkl',\n",
    "    gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
    "    batch_size=128,\n",
    "    type='train',\n",
    "    majority_fraction=0.01\n",
    ")\n",
    "test_loader = get_dataloader(\n",
    "    parquet_path='data/tf_gene_expression_labeled.parquet',\n",
    "    tf_sequences_path='data/tf_sequences.pkl',\n",
    "    gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
    "    batch_size=256,\n",
    "    type='test',\n",
    "    majority_fraction=0.01\n",
    ")\n",
    "\n",
    "print('Train size:', len(train_loader.dataset))\n",
    "print('Test size :', len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build TF and gene ID mappings from the training dataset\n",
    "# The dataset returns list-of-dicts as inputs; the underlying dataset object has `df` with tf_name/gene_name columns\n",
    "train_ds = train_loader.dataset\n",
    "tf_names = train_ds.df['tf_name'].unique().tolist()\n",
    "gene_names = train_ds.df['gene_name'].unique().tolist()\n",
    "\n",
    "tf_to_id = {n: i for i, n in enumerate(tf_names)}\n",
    "gene_to_id = {n: i for i, n in enumerate(gene_names)}\n",
    "\n",
    "num_tfs = len(tf_to_id)\n",
    "num_genes = len(gene_to_id)\n",
    "num_classes = len(train_ds.df['expression_label'].unique())\n",
    "\n",
    "print('Unique TFs (train):', num_tfs)\n",
    "print('Unique Genes (train):', num_genes)\n",
    "print('Num classes:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID-only model definition\n",
    "class TFGeneIDModel(nn.Module):\n",
    "    def __init__(self, num_tfs, num_genes, emb_dim=64, hidden_dim=256, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.tf_emb = nn.Embedding(num_tfs, emb_dim)\n",
    "        self.gene_emb = nn.Embedding(num_genes, emb_dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2*emb_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, tf_ids, gene_ids):\n",
    "        t = self.tf_emb(tf_ids)\n",
    "        g = self.gene_emb(gene_ids)\n",
    "        h = torch.cat([t, g], dim=-1)\n",
    "        return self.mlp(h)\n",
    "\n",
    "# Instantiate model\n",
    "model = TFGeneIDModel(num_tfs=num_tfs, num_genes=num_genes, emb_dim=64, hidden_dim=256, num_classes=num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training / evaluation helpers\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def prepare_id_batch(batch_x, device=device):\n",
    "    tf_ids = torch.tensor([tf_to_id[item['tf_name']] for item in batch_x], dtype=torch.long, device=device)\n",
    "    gene_ids = torch.tensor([gene_to_id[item['gene_name']] for item in batch_x], dtype=torch.long, device=device)\n",
    "    return tf_ids, gene_ids\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(loader)\n",
    "    for batch_x, batch_y in pbar:\n",
    "        batch_y = batch_y.to(device)\n",
    "        tf_ids, gene_ids = prepare_id_batch(batch_x)\n",
    "\n",
    "        logits = model(tf_ids, gene_ids)\n",
    "        loss = loss_fn(logits, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == batch_y).sum().item()\n",
    "        total += len(batch_y)\n",
    "        total_loss += loss.item() * len(batch_y)\n",
    "        pbar.set_postfix({'loss': total_loss/total, 'acc': total_correct/total})\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for batch_x, batch_y in loader:\n",
    "        batch_y = batch_y.to(device)\n",
    "        tf_ids, gene_ids = prepare_id_batch(batch_x)\n",
    "        logits = model(tf_ids, gene_ids)\n",
    "        loss = loss_fn(logits, batch_y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == batch_y).sum().item()\n",
    "        total += len(batch_y)\n",
    "        total_loss += loss.item() * len(batch_y)\n",
    "    return total_loss/total, total_correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for a few epochs\n",
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, test_loader)\n",
    "    print(f'Epoch {epoch:02d} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Save model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'tf_to_id': tf_to_id,\n",
    "    'gene_to_id': gene_to_id\n",
    "}, 'models/tf_gene_id_baseline.pt')\n",
    "print('Saved model to models/tf_gene_id_baseline.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
