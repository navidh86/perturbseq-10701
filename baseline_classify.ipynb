{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navidh86/perturbseq-10701/blob/master/baseline_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2e5d23ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e5d23ad",
        "outputId": "fa0e2543-e241-4d19-d77a-1898fffde35b"
      },
      "outputs": [],
      "source": [
        "# # ONLY FOR COLAB\n",
        "# !git clone https://github.com/navidh86/perturbseq-10701.git\n",
        "# %cd ./perturbseq-10701\n",
        "# !pip install fastparquet tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "VptI-6ncTr-5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VptI-6ncTr-5",
        "outputId": "8bbad7a8-dace-4848-f98a-3988396bfa01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Imports and device\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from data.reference_data_classification import get_dataloader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8b6f32b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b6f32b1",
        "outputId": "0577db65-95a4-4d78-acab-42e81f2c7c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 10845\n",
            "Val size  : 2324\n",
            "Test size : 2325\n"
          ]
        }
      ],
      "source": [
        "# # Create dataloaders (point to data/ paths explicitly)\n",
        "# train_loader = get_dataloader(\n",
        "#     parquet_path='data/tf_gene_expression_labeled_v2.parquet',\n",
        "#     tf_sequences_path='data/tf_sequences.pkl',\n",
        "#     gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
        "#     batch_size=128,\n",
        "#     type='train',\n",
        "#     majority_fraction=0.005\n",
        "# )\n",
        "# test_loader = get_dataloader(\n",
        "#     parquet_path='data/tf_gene_expression_labeled_v2.parquet',\n",
        "#     tf_sequences_path='data/tf_sequences.pkl',\n",
        "#     gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
        "#     batch_size=256,\n",
        "#     type='test',\n",
        "#     majority_fraction=0.005\n",
        "# )\n",
        "\n",
        "# print('Train size:', len(train_loader.dataset))\n",
        "# print('Test size :', len(test_loader.dataset))\n",
        "\n",
        "# ========================\n",
        "# Load Dataloaders\n",
        "# ========================\n",
        "# Create dataloaders (train / val / test)\n",
        "train_loader = get_dataloader(\n",
        "    parquet_path='data/tf_gene_expression_labeled_v2.parquet',\n",
        "    tf_sequences_path='data/tf_sequences.pkl',\n",
        "    gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
        "    batch_size=128,\n",
        "    type='train',\n",
        "    majority_fraction=0.005,\n",
        ")\n",
        "\n",
        "val_loader = get_dataloader(\n",
        "    parquet_path='data/tf_gene_expression_labeled_v2.parquet',\n",
        "    tf_sequences_path='data/tf_sequences.pkl',\n",
        "    gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
        "    batch_size=256,\n",
        "    type='val',\n",
        "    majority_fraction=0.005,\n",
        ")\n",
        "\n",
        "test_loader = get_dataloader(\n",
        "    parquet_path='data/tf_gene_expression_labeled_v2.parquet',\n",
        "    tf_sequences_path='data/tf_sequences.pkl',\n",
        "    gene_sequences_path='data/gene_sequences_4000bp.pkl',\n",
        "    batch_size=256,\n",
        "    type='test',\n",
        "    majority_fraction=0.005,\n",
        ")\n",
        "\n",
        "print('Train size:', len(train_loader.dataset))\n",
        "print('Val size  :', len(val_loader.dataset))\n",
        "print('Test size :', len(test_loader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "15c9f72b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15c9f72b",
        "outputId": "1fc7012e-2170-46bc-d68c-2a1cb1e0cf20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique TFs (all splits): 223\n",
            "Unique Genes (all splits): 4539\n"
          ]
        }
      ],
      "source": [
        "# Build TF/Gene ID maps using ALL (train + val + test)\n",
        "train_ds = train_loader.dataset\n",
        "val_ds = val_loader.dataset\n",
        "test_ds = test_loader.dataset\n",
        "\n",
        "combined_df = pd.concat([train_ds.df, val_ds.df, test_ds.df]).reset_index(drop=True)\n",
        "\n",
        "# Unique names\n",
        "tf_names = combined_df['tf_name'].unique().tolist()\n",
        "gene_names = combined_df['gene_name'].unique().tolist()\n",
        "\n",
        "# Mappings\n",
        "tf_to_id = {n: i for i, n in enumerate(tf_names)}\n",
        "gene_to_id = {n: i for i, n in enumerate(gene_names)}\n",
        "\n",
        "num_tfs = len(tf_to_id)\n",
        "num_genes = len(gene_to_id)\n",
        "\n",
        "print('Unique TFs (all splits):', num_tfs)\n",
        "print('Unique Genes (all splits):', num_genes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Fn0lV1UaWo7K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn0lV1UaWo7K",
        "outputId": "161503d2-5761-46f1-d90d-dd6faef93957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFs in cache: 223\n",
            "Genes in cache: 5307\n",
            "Num classes: 3\n"
          ]
        }
      ],
      "source": [
        "# Load cached embeddings and prepare name lists\n",
        "import pickle\n",
        "\n",
        "# Load cached TF/gene embeddings produced by the embedding notebook\n",
        "tf_embed_cache = pickle.load(open('embeds/tf_cls.pkl', 'rb'))\n",
        "gene_embed_cache = pickle.load(open('embeds/gn_cls.pkl', 'rb'))\n",
        "\n",
        "# Convert any numpy arrays to torch tensors\n",
        "for k in list(tf_embed_cache.keys()):\n",
        "    v = tf_embed_cache[k]\n",
        "    if not isinstance(v, torch.Tensor):\n",
        "        tf_embed_cache[k] = torch.tensor(v, dtype=torch.float32)\n",
        "for k in list(gene_embed_cache.keys()):\n",
        "    v = gene_embed_cache[k]\n",
        "    if not isinstance(v, torch.Tensor):\n",
        "        gene_embed_cache[k] = torch.tensor(v, dtype=torch.float32)\n",
        "\n",
        "# Expose name lists and counts (from the caches to ensure consistent mapping)\n",
        "tf_names = list(tf_embed_cache.keys())\n",
        "gene_names = list(gene_embed_cache.keys())\n",
        "num_tfs = len(tf_names)\n",
        "num_genes = len(gene_names)\n",
        "# number of classes is taken from the training split\n",
        "num_classes = len(train_loader.dataset.df['expression_label'].unique())\n",
        "\n",
        "print('TFs in cache:', num_tfs)\n",
        "print('Genes in cache:', num_genes)\n",
        "print('Num classes:', num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "af14d080",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af14d080",
        "outputId": "3fe77654-92c6-4f08-f23e-ff4c090ccc18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFGeneIDModel(\n",
            "  (tf_emb): Embedding(223, 64)\n",
            "  (gene_emb): Embedding(5307, 64)\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Linear(in_features=128, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# ID-only model definition\n",
        "class TFGeneIDModel(nn.Module):\n",
        "    def __init__(self, num_tfs, num_genes, emb_dim=64, hidden_dim=256, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.tf_emb = nn.Embedding(num_tfs, emb_dim)\n",
        "        self.gene_emb = nn.Embedding(num_genes, emb_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2*emb_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim//2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, tf_ids, gene_ids):\n",
        "        t = self.tf_emb(tf_ids)\n",
        "        g = self.gene_emb(gene_ids)\n",
        "        h = torch.cat([t, g], dim=-1)\n",
        "        return self.mlp(h)\n",
        "\n",
        "# Instantiate model\n",
        "model = TFGeneIDModel(num_tfs=num_tfs, num_genes=num_genes, emb_dim=64, hidden_dim=256, num_classes=num_classes).to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "87abaa78",
      "metadata": {
        "id": "87abaa78"
      },
      "outputs": [],
      "source": [
        "# Training / evaluation helpers\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def prepare_id_batch(batch_x, device=device):\n",
        "    tf_ids = torch.tensor([tf_to_id[item['tf_name']] for item in batch_x], dtype=torch.long, device=device)\n",
        "    gene_ids = torch.tensor([gene_to_id[item['gene_name']] for item in batch_x], dtype=torch.long, device=device)\n",
        "    return tf_ids, gene_ids\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    pbar = tqdm(loader)\n",
        "    for batch_x, batch_y in pbar:\n",
        "        batch_y = batch_y.to(device)\n",
        "        tf_ids, gene_ids = prepare_id_batch(batch_x)\n",
        "\n",
        "        logits = model(tf_ids, gene_ids)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total += len(batch_y)\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        pbar.set_postfix({'loss': total_loss/total, 'acc': total_correct/total})\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "        tf_ids, gene_ids = prepare_id_batch(batch_x)\n",
        "        logits = model(tf_ids, gene_ids)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total += len(batch_y)\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "    return total_loss/total, total_correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ccb36c78",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final evaluation (nt_classify-style): compute loss, accuracy, macro-F1, and classification report\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import json\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model_ntstyle(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        # support both cache-based and id-based models\n",
        "        try:\n",
        "            logits = model(batch_x)\n",
        "        except TypeError:\n",
        "            tf_ids, gene_ids = prepare_id_batch(batch_x, device=device)\n",
        "            logits = model(tf_ids, gene_ids)\n",
        "\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    return avg_loss, accuracy, macro_f1, all_labels, all_preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "399d02d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "399d02d1",
        "outputId": "311dda1b-c2e7-4f96-c35c-7eea0b683c68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 50.35it/s, loss=0.954, acc=0.519]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | Train Loss: 0.9543, Train Acc: 0.5192 Train F1: 0.6334 | Val Loss: 0.8542, Val Acc: 0.5869, Val F1: 0.5793\n",
            "***Saved new best model at epoch 1 (Val F1=0.5793)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 55.98it/s, loss=0.784, acc=0.635]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 02 | Train Loss: 0.7841, Train Acc: 0.6349 Train F1: 0.6949 | Val Loss: 0.7824, Val Acc: 0.6205, Val F1: 0.6157\n",
            "***Saved new best model at epoch 2 (Val F1=0.6157)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 54.46it/s, loss=0.699, acc=0.686]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 03 | Train Loss: 0.6992, Train Acc: 0.6857 Train F1: 0.7378 | Val Loss: 0.7627, Val Acc: 0.6321, Val F1: 0.6327\n",
            "***Saved new best model at epoch 3 (Val F1=0.6327)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 57.12it/s, loss=0.624, acc=0.726]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 04 | Train Loss: 0.6239, Train Acc: 0.7261 Train F1: 0.7888 | Val Loss: 0.7478, Val Acc: 0.6446, Val F1: 0.6491\n",
            "***Saved new best model at epoch 4 (Val F1=0.6491)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 62.27it/s, loss=0.553, acc=0.764]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 05 | Train Loss: 0.5532, Train Acc: 0.7639 Train F1: 0.8332 | Val Loss: 0.7423, Val Acc: 0.6652, Val F1: 0.6702\n",
            "***Saved new best model at epoch 5 (Val F1=0.6702)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 59.63it/s, loss=0.503, acc=0.786]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 06 | Train Loss: 0.5029, Train Acc: 0.7864 Train F1: 0.8570 | Val Loss: 0.7491, Val Acc: 0.6670, Val F1: 0.6704\n",
            "***Saved new best model at epoch 6 (Val F1=0.6704)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.96it/s, loss=0.44, acc=0.814] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 07 | Train Loss: 0.4398, Train Acc: 0.8142 Train F1: 0.8952 | Val Loss: 0.7670, Val Acc: 0.6807, Val F1: 0.6851\n",
            "***Saved new best model at epoch 7 (Val F1=0.6851)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 61.79it/s, loss=0.384, acc=0.844]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 08 | Train Loss: 0.3843, Train Acc: 0.8437 Train F1: 0.9060 | Val Loss: 0.7930, Val Acc: 0.6760, Val F1: 0.6776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 64.91it/s, loss=0.343, acc=0.864]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 09 | Train Loss: 0.3433, Train Acc: 0.8644 Train F1: 0.9348 | Val Loss: 0.8263, Val Acc: 0.6833, Val F1: 0.6877\n",
            "***Saved new best model at epoch 9 (Val F1=0.6877)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.40it/s, loss=0.301, acc=0.881]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Train Loss: 0.3011, Train Acc: 0.8814 Train F1: 0.9424 | Val Loss: 0.8909, Val Acc: 0.6889, Val F1: 0.6944\n",
            "***Saved new best model at epoch 10 (Val F1=0.6944)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 54.23it/s, loss=0.274, acc=0.891]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 | Train Loss: 0.2739, Train Acc: 0.8908 Train F1: 0.9578 | Val Loss: 0.9085, Val Acc: 0.6863, Val F1: 0.6907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.44it/s, loss=0.241, acc=0.904]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 | Train Loss: 0.2410, Train Acc: 0.9042 Train F1: 0.9626 | Val Loss: 0.9720, Val Acc: 0.6846, Val F1: 0.6896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 60.77it/s, loss=0.219, acc=0.914]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 | Train Loss: 0.2187, Train Acc: 0.9137 Train F1: 0.9667 | Val Loss: 1.0116, Val Acc: 0.6923, Val F1: 0.6965\n",
            "***Saved new best model at epoch 13 (Val F1=0.6965)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 57.57it/s, loss=0.189, acc=0.923]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 | Train Loss: 0.1888, Train Acc: 0.9231 Train F1: 0.9768 | Val Loss: 1.0551, Val Acc: 0.6928, Val F1: 0.6974\n",
            "***Saved new best model at epoch 14 (Val F1=0.6974)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 54.37it/s, loss=0.175, acc=0.932]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 | Train Loss: 0.1752, Train Acc: 0.9322 Train F1: 0.9817 | Val Loss: 1.0910, Val Acc: 0.6842, Val F1: 0.6896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 59.13it/s, loss=0.161, acc=0.939]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 | Train Loss: 0.1607, Train Acc: 0.9392 Train F1: 0.9806 | Val Loss: 1.1580, Val Acc: 0.6799, Val F1: 0.6840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 59.67it/s, loss=0.145, acc=0.942]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 | Train Loss: 0.1450, Train Acc: 0.9424 Train F1: 0.9881 | Val Loss: 1.1951, Val Acc: 0.6889, Val F1: 0.6937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 55.92it/s, loss=0.126, acc=0.95] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 | Train Loss: 0.1262, Train Acc: 0.9498 Train F1: 0.9916 | Val Loss: 1.2741, Val Acc: 0.6872, Val F1: 0.6928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 55.56it/s, loss=0.115, acc=0.957]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 | Train Loss: 0.1153, Train Acc: 0.9570 Train F1: 0.9934 | Val Loss: 1.2745, Val Acc: 0.6936, Val F1: 0.6968\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 63.59it/s, loss=0.106, acc=0.961] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 | Train Loss: 0.1059, Train Acc: 0.9609 Train F1: 0.9945 | Val Loss: 1.3625, Val Acc: 0.6898, Val F1: 0.6943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 57.19it/s, loss=0.103, acc=0.961] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 | Train Loss: 0.1035, Train Acc: 0.9612 Train F1: 0.9943 | Val Loss: 1.3569, Val Acc: 0.6919, Val F1: 0.6963\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 55.77it/s, loss=0.0932, acc=0.964]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 | Train Loss: 0.0932, Train Acc: 0.9637 Train F1: 0.9966 | Val Loss: 1.4121, Val Acc: 0.6954, Val F1: 0.6996\n",
            "***Saved new best model at epoch 22 (Val F1=0.6996)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 57.08it/s, loss=0.087, acc=0.968] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 | Train Loss: 0.0870, Train Acc: 0.9675 Train F1: 0.9963 | Val Loss: 1.4403, Val Acc: 0.6941, Val F1: 0.6981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.87it/s, loss=0.0783, acc=0.971]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 | Train Loss: 0.0783, Train Acc: 0.9711 Train F1: 0.9957 | Val Loss: 1.4797, Val Acc: 0.6807, Val F1: 0.6862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 59.63it/s, loss=0.0715, acc=0.972]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 | Train Loss: 0.0715, Train Acc: 0.9722 Train F1: 0.9966 | Val Loss: 1.5037, Val Acc: 0.6992, Val F1: 0.7027\n",
            "***Saved new best model at epoch 25 (Val F1=0.7027)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 57.38it/s, loss=0.0753, acc=0.972]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 | Train Loss: 0.0753, Train Acc: 0.9721 Train F1: 0.9968 | Val Loss: 1.5727, Val Acc: 0.6880, Val F1: 0.6929\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.78it/s, loss=0.0703, acc=0.973]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 | Train Loss: 0.0703, Train Acc: 0.9731 Train F1: 0.9984 | Val Loss: 1.5918, Val Acc: 0.6958, Val F1: 0.6998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 64.54it/s, loss=0.0623, acc=0.978]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 | Train Loss: 0.0623, Train Acc: 0.9782 Train F1: 0.9989 | Val Loss: 1.6435, Val Acc: 0.6949, Val F1: 0.6991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.73it/s, loss=0.0534, acc=0.98] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 | Train Loss: 0.0534, Train Acc: 0.9797 Train F1: 0.9990 | Val Loss: 1.6911, Val Acc: 0.6936, Val F1: 0.6987\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:01<00:00, 56.07it/s, loss=0.0508, acc=0.982]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 | Train Loss: 0.0508, Train Acc: 0.9816 Train F1: 0.9987 | Val Loss: 1.7693, Val Acc: 0.6910, Val F1: 0.6945\n",
            "\n",
            "Training complete.\n",
            "Best Validation F1: 0.7026722653077618\n"
          ]
        }
      ],
      "source": [
        "# # Train for a few epochs\n",
        "# num_epochs = 30\n",
        "# for epoch in range(1, num_epochs+1):\n",
        "#     train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "#     val_loss, val_acc = evaluate(model, test_loader)\n",
        "#     print(f'Epoch {epoch:02d} | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "# # Save model\n",
        "# os.makedirs('models', exist_ok=True)\n",
        "# torch.save({\n",
        "#     'model_state_dict': model.state_dict(),\n",
        "#     'tf_to_id': tf_to_id,\n",
        "#     'gene_to_id': gene_to_id\n",
        "# }, 'models/tf_gene_id_baseline.pt')\n",
        "# print('Saved model to models/tf_gene_id_baseline.pt')\n",
        "\n",
        "# ================================\n",
        "# Training Loop WITH VALIDATION\n",
        "# ================================\n",
        "\n",
        "num_epochs = 30\n",
        "best_val_f1 = -1\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "    val_loss, val_acc = evaluate(model, val_loader)\n",
        "\n",
        "    # compute F1 on train set\n",
        "    _, _, train_f1, _, _ = eval_model_ntstyle(model, train_loader)\n",
        "\n",
        "    # compute F1 on val set\n",
        "    _, _, val_f1, _, _ = eval_model_ntstyle(model, val_loader)\n",
        "\n",
        "    print(f'Epoch {epoch:02d} | '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} Train F1: {train_f1:.4f} | '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "    # SAVE BEST MODEL (based on val F1)\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_state = model.state_dict()\n",
        "        torch.save(best_state, 'models/best_model.pt')\n",
        "        print(f'***Saved new best model at epoch {epoch} (Val F1={val_f1:.4f})')\n",
        "\n",
        "print(\"\\nTraining complete.\")\n",
        "print(\"Best Validation F1:\", best_val_f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "xvHPJ77iXYeE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvHPJ77iXYeE",
        "outputId": "dee0ad99-1ecd-4bab-b4a8-b607c89fea25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FINAL TEST RESULTS (BEST CHECKPOINT) ===\n",
            "Test Accuracy: 0.7010752688172043\n",
            "Test Macro F1: 0.7033612089520026\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6826    0.7076    0.6949       766\n",
            "           1     0.7860    0.8140    0.7997       731\n",
            "           2     0.6370    0.5954    0.6155       828\n",
            "\n",
            "    accuracy                         0.7011      2325\n",
            "   macro avg     0.7019    0.7056    0.7034      2325\n",
            "weighted avg     0.6989    0.7011    0.6996      2325\n",
            "\n",
            "\n",
            "Saved metrics to results/best_model_test_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# =======================================\n",
        "# Final evaluation on TEST using best model\n",
        "# =======================================\n",
        "\n",
        "# load best checkpoint\n",
        "model.load_state_dict(torch.load('models/best_model.pt'))\n",
        "\n",
        "test_loss, test_acc, test_f1, y_true, y_pred = eval_model_ntstyle(model, test_loader)\n",
        "\n",
        "print(\"\\n=== FINAL TEST RESULTS (BEST CHECKPOINT) ===\")\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"Test Macro F1:\", test_f1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# Save JSON\n",
        "os.makedirs('results', exist_ok=True)\n",
        "metrics = {\n",
        "    'test_loss': float(test_loss),\n",
        "    'accuracy': float(test_acc),\n",
        "    'macro_f1': float(test_f1),\n",
        "    'classification_report': classification_report(y_true, y_pred, digits=4),\n",
        "}\n",
        "with open('results/best_model_test_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "\n",
        "print('\\nSaved metrics to results/best_model_test_metrics.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SKZQRQlcM7DG",
      "metadata": {
        "id": "SKZQRQlcM7DG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torchgpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
