{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXdctc4hCjFJVN/j7535Vt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navidh86/perturbseq-10701/blob/master/nt_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyG_N0YZoyDa",
        "outputId": "0d1977c3-f353-4f5a-ac58-f87fb9b6b17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'perturbseq-10701'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 141 (delta 10), reused 14 (delta 6), pack-reused 121 (from 2)\u001b[K\n",
            "Receiving objects: 100% (141/141), 252.09 MiB | 22.77 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "Updating files: 100% (43/43), done.\n",
            "/content/perturbseq-10701\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastparquet) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n"
          ]
        }
      ],
      "source": [
        "# ONLY FOR COLAB\n",
        "!git clone https://github.com/navidh86/perturbseq-10701.git\n",
        "%cd ./perturbseq-10701\n",
        "!pip install fastparquet tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96_JcF_xpCQw",
        "outputId": "84b7f130-fc44-436d-f2bd-d8e81f92fde1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-g5ry4yxe\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-g5ry4yxe\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit bc7a268fed343ab22446ec86115cf2727b38a5eb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\n",
            "Collecting huggingface-hub<2.0,>=1.0.0 (from transformers==5.0.0.dev0)\n",
            "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.22.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.20.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2025.11.12)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.0.0->transformers==5.0.0.dev0) (1.3.1)\n",
            "Downloading huggingface_hub-1.1.7-py3-none-any.whl (516 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.2/516.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=10861080 sha256=83c917c4be27f2957a8a2cd9a86ecd7ab38d2fb3c48f4f030673794b2da7c4b5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hvevh379/wheels/54/cb/3f/83103de5575c534436d6a4686686dead458238dfaf1147e98d\n",
            "Successfully built transformers\n",
            "Installing collected packages: huggingface-hub, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.2\n",
            "    Uninstalling transformers-4.57.2:\n",
            "      Successfully uninstalled transformers-4.57.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-1.1.7 transformers-5.0.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "OB69xvlgpKcB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reference_data_classification import (\n",
        "    PairPerturbSeqDataset,\n",
        "    perturbseq_collate_2,\n",
        "    get_dataloader\n",
        ")\n",
        "\n",
        "train_loader = get_dataloader(\n",
        "    parquet_path=\"tf_gene_expression_labeled.parquet\",\n",
        "    tf_sequences_path=\"tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"gene_sequences_4000bp.pkl\",\n",
        "    batch_size=32,\n",
        "    type=\"train\",\n",
        "    majority_fraction=0.01\n",
        ")\n",
        "\n",
        "test_loader = get_dataloader(\n",
        "    parquet_path=\"tf_gene_expression_labeled.parquet\",\n",
        "    tf_sequences_path=\"tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"gene_sequences_4000bp.pkl\",\n",
        "    batch_size=32,\n",
        "    type=\"test\",\n",
        "    majority_fraction=0.01\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(train_loader.dataset))\n",
        "print(\"Test size: \", len(test_loader.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73I8yRgzpZwo",
        "outputId": "ce9d9097-a64b-4c71-d62a-2a082314d602"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 23427\n",
            "Test size:  5858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "# Load cached embeddings\n",
        "tf_embed_cache = pickle.load(open(\"./embeds/tf_cls.pkl\", \"rb\"))\n",
        "gene_embed_cache = pickle.load(open(\"./embeds/gn_cls.pkl\", \"rb\"))\n",
        "\n",
        "# Convert all embeddings to torch tensors (if stored as numpy)\n",
        "for k in tf_embed_cache:\n",
        "    if not isinstance(tf_embed_cache[k], torch.Tensor):\n",
        "        tf_embed_cache[k] = torch.tensor(tf_embed_cache[k], dtype=torch.float32)\n",
        "\n",
        "for k in gene_embed_cache:\n",
        "    if not isinstance(gene_embed_cache[k], torch.Tensor):\n",
        "        gene_embed_cache[k] = torch.tensor(gene_embed_cache[k], dtype=torch.float32)\n",
        "\n",
        "# Inspect shapes\n",
        "first_tf = next(iter(tf_embed_cache.values()))\n",
        "first_gene = next(iter(gene_embed_cache.values()))\n",
        "\n",
        "print(\"TF embedding count:\", len(tf_embed_cache))\n",
        "print(\"Gene embedding count:\", len(gene_embed_cache))\n",
        "print(\"TF embedding dim:\", first_tf.shape)\n",
        "print(\"Gene embedding dim:\", first_gene.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qMY0NZ7u9jD",
        "outputId": "837c1702-edf5-46ba-c503-d9f9e4038848"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF embedding count: 223\n",
            "Gene embedding count: 5307\n",
            "TF embedding dim: torch.Size([1280])\n",
            "Gene embedding dim: torch.Size([1280])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionMLP(nn.Module):\n",
        "    def __init__(self, tf_embed_cache, gene_embed_cache, hidden_dim=1024, num_classes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tf_embed_cache = tf_embed_cache\n",
        "        self.gene_embed_cache = gene_embed_cache\n",
        "\n",
        "        tf_dim = next(iter(tf_embed_cache.values())).shape[0]\n",
        "        gene_dim = next(iter(gene_embed_cache.values())).shape[0]\n",
        "\n",
        "        in_dim = tf_dim + gene_dim   # 1280 + 1280\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(hidden_dim // 2, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, num_classes)   # logits for 3 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_x):\n",
        "        \"\"\"\n",
        "        batch_x = list of dicts:\n",
        "        [\n",
        "           {\"tf_name\": ..., \"gene_name\": ...},\n",
        "           ...\n",
        "        ]\n",
        "        \"\"\"\n",
        "        vectors = []\n",
        "\n",
        "        for item in batch_x:\n",
        "            tf_vec = self.tf_embed_cache[item[\"tf_name\"]]\n",
        "            gene_vec = self.gene_embed_cache[item[\"gene_name\"]]\n",
        "            pair_vec = torch.cat([tf_vec, gene_vec], dim=-1)\n",
        "            vectors.append(pair_vec)\n",
        "\n",
        "        X = torch.stack(vectors).to(device)\n",
        "        return self.net(X)   # shape (batch, 3)\n"
      ],
      "metadata": {
        "id": "bldOROT3pcHf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InteractionMLP2(nn.Module):\n",
        "    def __init__(self, tf_embed_cache, gene_embed_cache, hidden_dim=1024, num_classes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tf_cache = tf_embed_cache\n",
        "        self.gene_cache = gene_embed_cache\n",
        "\n",
        "        tf_dim = next(iter(tf_embed_cache.values())).shape[0]\n",
        "        gene_dim = next(iter(gene_embed_cache.values())).shape[0]\n",
        "\n",
        "        in_dim = tf_dim + gene_dim + tf_dim  # concat + product\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(hidden_dim//2, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_x):\n",
        "        vecs = []\n",
        "        for item in batch_x:\n",
        "            tf = self.tf_cache[item[\"tf_name\"]]\n",
        "            gene = self.gene_cache[item[\"gene_name\"]]\n",
        "            inter = tf * gene  # IMPORTANT\n",
        "            vecs.append(torch.cat([tf, gene, inter], dim=-1))\n",
        "        x = torch.stack(vecs).to(device)\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "fhYoqDhA0rMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        logits = model(batch_x)  # shape (B, 3)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "    return total_loss/total_samples, total_correct/total_samples\n"
      ],
      "metadata": {
        "id": "gCF8Zdvps8fX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0, 0, 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        logits = model(batch_x)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = total_correct / total_samples\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    return avg_loss, accuracy, macro_f1, all_labels, all_preds\n"
      ],
      "metadata": {
        "id": "63H3zaUds-fv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InteractionMLP2(\n",
        "    tf_embed_cache=tf_embed_cache,\n",
        "    gene_embed_cache=gene_embed_cache\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "BieWsT4es_tX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "    test_loss, test_acc, test_f1, _, _ = eval_model(model, test_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "          f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw7irBwStEpo",
        "outputId": "835bd97a-dd50-4e3b-e627-337021dffa5a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 1.0910, Train Acc: 0.3945 | Test Loss: 1.0885, Test Acc: 0.3981, Test F1: 0.1898\n",
            "Epoch 02 | Train Loss: 1.0888, Train Acc: 0.3981 | Test Loss: 1.0869, Test Acc: 0.3981, Test F1: 0.1898\n",
            "Epoch 03 | Train Loss: 1.0860, Train Acc: 0.3981 | Test Loss: 1.0894, Test Acc: 0.3981, Test F1: 0.1898\n",
            "Epoch 04 | Train Loss: 1.0733, Train Acc: 0.4158 | Test Loss: 1.0697, Test Acc: 0.4133, Test F1: 0.2264\n",
            "Epoch 05 | Train Loss: 1.0424, Train Acc: 0.4570 | Test Loss: 1.0315, Test Acc: 0.4850, Test F1: 0.3682\n",
            "Epoch 06 | Train Loss: 1.0361, Train Acc: 0.4465 | Test Loss: 1.0137, Test Acc: 0.4843, Test F1: 0.3804\n",
            "Epoch 07 | Train Loss: 1.0206, Train Acc: 0.4568 | Test Loss: 1.0482, Test Acc: 0.4423, Test F1: 0.4095\n",
            "Epoch 08 | Train Loss: 1.0141, Train Acc: 0.4569 | Test Loss: 0.9785, Test Acc: 0.5205, Test F1: 0.4852\n",
            "Epoch 09 | Train Loss: 1.0018, Train Acc: 0.4728 | Test Loss: 0.9577, Test Acc: 0.5159, Test F1: 0.3947\n",
            "Epoch 10 | Train Loss: 0.9985, Train Acc: 0.4712 | Test Loss: 0.9868, Test Acc: 0.4923, Test F1: 0.3885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_f1, y_true, y_pred = eval_model(model, test_loader)\n",
        "\n",
        "print(\"Final Test Accuracy:\", test_acc)\n",
        "print(\"Final Test Macro F1:\", test_f1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcM3VCLqvCN3",
        "outputId": "706ff8e1-199b-42cc-f585-87efdbe7f2e5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.49231819733697507\n",
            "Final Test Macro F1: 0.38852434226512056\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000      1654\n",
            "           1     0.7096    0.5952    0.6474      2332\n",
            "           2     0.3834    0.7991    0.5182      1872\n",
            "\n",
            "    accuracy                         0.4923      5858\n",
            "   macro avg     0.3643    0.4648    0.3885      5858\n",
            "weighted avg     0.4050    0.4923    0.4233      5858\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNjClJPnvYPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}