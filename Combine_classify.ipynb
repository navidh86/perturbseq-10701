{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObGJUrARrQwVaH6mGvhSrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navidh86/perturbseq-10701/blob/master/Combine_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u73MkAaotApU",
        "outputId": "0ba8be14-6e15-4099-e7fb-0a350a0eeec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'perturbseq-10701'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 198 (delta 37), reused 45 (delta 16), pack-reused 121 (from 2)\u001b[K\n",
            "Receiving objects: 100% (198/198), 260.56 MiB | 23.32 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "Updating files: 100% (52/52), done.\n",
            "/content/perturbseq-10701/perturbseq-10701\n",
            "Requirement already satisfied: fastparquet in /usr/local/lib/python3.12/dist-packages (2024.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastparquet) (25.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# ONLY FOR COLAB\n",
        "!git clone https://github.com/navidh86/perturbseq-10701.git\n",
        "%cd ./perturbseq-10701\n",
        "!pip install fastparquet tqdm scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zIrLgcqtGSH",
        "outputId": "4a71d759-ead2-4f77-a9c1-8704d8aefa3b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data.reference_data_classification import (\n",
        "    PairPerturbSeqDataset,\n",
        "    perturbseq_collate_2,\n",
        "    get_dataloader,\n",
        ")\n",
        "\n",
        "train_loader = get_dataloader(\n",
        "    parquet_path=\"data/tf_gene_expression_labeled_v2.parquet\",\n",
        "    tf_sequences_path=\"data/tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"data/gene_sequences_4000bp.pkl\",\n",
        "    batch_size=64,\n",
        "    type=\"train\",\n",
        "    majority_fraction=0.005\n",
        ")\n",
        "\n",
        "test_loader = get_dataloader(\n",
        "    parquet_path=\"data/tf_gene_expression_labeled_v2.parquet\",\n",
        "    tf_sequences_path=\"data/tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"data/gene_sequences_4000bp.pkl\",\n",
        "    batch_size=64,\n",
        "    type=\"test\",\n",
        "    majority_fraction=0.005\n",
        ")\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Test batches: \", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzYUjGv8tNC6",
        "outputId": "e30d723e-7f76-41e8-b39e-ba462fdd3f6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 170\n",
            "Test batches:  37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load NT sequence embeddings\n",
        "tf_embed_cache = pickle.load(open(\"./embeds/tf_cls.pkl\", \"rb\"))\n",
        "gene_embed_cache = pickle.load(open(\"./embeds/gn_cls.pkl\", \"rb\"))\n",
        "\n",
        "# ensure everything is torch tensors\n",
        "for k in tf_embed_cache:\n",
        "    if not isinstance(tf_embed_cache[k], torch.Tensor):\n",
        "        tf_embed_cache[k] = torch.tensor(tf_embed_cache[k], dtype=torch.float32)\n",
        "\n",
        "for k in gene_embed_cache:\n",
        "    if not isinstance(gene_embed_cache[k], torch.Tensor):\n",
        "        gene_embed_cache[k] = torch.tensor(gene_embed_cache[k], dtype=torch.float32)\n",
        "\n",
        "first_tf = next(iter(tf_embed_cache.values()))\n",
        "first_gene = next(iter(gene_embed_cache.values()))\n",
        "print(\"TF emb dim:\", first_tf.shape)\n",
        "print(\"Gene emb dim:\", first_gene.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbIFh874tVmi",
        "outputId": "ef712f7b-51f7-4cbd-adab-44f1bf9ac5f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF emb dim: torch.Size([1280])\n",
            "Gene emb dim: torch.Size([1280])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_loader.dataset\n",
        "test_ds = test_loader.dataset\n",
        "\n",
        "# union of names from train + test\n",
        "tf_names = sorted(set(train_ds.df[\"tf_name\"].tolist() + test_ds.df[\"tf_name\"].tolist()))\n",
        "gene_names = sorted(set(train_ds.df[\"gene_name\"].tolist() + test_ds.df[\"gene_name\"].tolist()))\n",
        "\n",
        "tf_id_map = {name: idx for idx, name in enumerate(tf_names)}\n",
        "gene_id_map = {name: idx for idx, name in enumerate(gene_names)}\n",
        "\n",
        "print(\"Num TF IDs:\", len(tf_id_map))\n",
        "print(\"Num gene IDs:\", len(gene_id_map))\n",
        "\n",
        "# quick sanity check: names in map also have embeddings\n",
        "missing_tf = [n for n in tf_names if n not in tf_embed_cache]\n",
        "missing_gene = [n for n in gene_names if n not in gene_embed_cache]\n",
        "print(\"Missing TF in cache:\", len(missing_tf))\n",
        "print(\"Missing gene in cache:\", len(missing_gene))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-8aBFMpuSuL",
        "outputId": "bb961f6a-1308-480a-9ac7-f25028725619"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num TF IDs: 223\n",
            "Num gene IDs: 4305\n",
            "Missing TF in cache: 0\n",
            "Missing gene in cache: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(index, num_classes):\n",
        "    v = torch.zeros(num_classes, dtype=torch.float32)\n",
        "    v[index] = 1.0\n",
        "    return v\n"
      ],
      "metadata": {
        "id": "7ih5IJ4UxIO7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TFgeneHybridMLP(nn.Module):\n",
        "    def __init__(self, tf_embed_cache, gene_embed_cache, tf_id_map, gene_id_map,\n",
        "                 hidden_dim=1024, num_classes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tf_cache = tf_embed_cache\n",
        "        self.gene_cache = gene_embed_cache\n",
        "        self.tf_id_map = tf_id_map\n",
        "        self.gene_id_map = gene_id_map\n",
        "\n",
        "        self.num_tfs = len(tf_id_map)\n",
        "        self.num_genes = len(gene_id_map)\n",
        "\n",
        "        seq_dim = next(iter(tf_embed_cache.values())).shape[0]\n",
        "\n",
        "        # FINAL INPUT SIZE:\n",
        "        # TF_seq + Gene_seq + interaction + TF_onehot + Gene_onehot\n",
        "        in_dim = seq_dim*3 + self.num_tfs + self.num_genes\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(hidden_dim//2, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_x):\n",
        "        X_list = []\n",
        "\n",
        "        for item in batch_x:\n",
        "            tf_name = item[\"tf_name\"]\n",
        "            gene_name = item[\"gene_name\"]\n",
        "\n",
        "            tf_seq = self.tf_cache[tf_name]\n",
        "            gene_seq = self.gene_cache[gene_name]\n",
        "            interaction = tf_seq * gene_seq\n",
        "\n",
        "            tf_onehot = torch.zeros(self.num_tfs)\n",
        "            gene_onehot = torch.zeros(self.num_genes)\n",
        "\n",
        "            tf_onehot[self.tf_id_map[tf_name]] = 1.0\n",
        "            gene_onehot[self.gene_id_map[gene_name]] = 1.0\n",
        "\n",
        "            vec = torch.cat([tf_seq, gene_seq, interaction, tf_onehot, gene_onehot])\n",
        "            X_list.append(vec)\n",
        "\n",
        "        X = torch.stack(X_list).to(device)\n",
        "        return self.net(X)\n"
      ],
      "metadata": {
        "id": "eNIK6aS1uYyD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        logits = model(batch_x)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        logits = model(batch_x)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    acc = total_correct / total_samples\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    return avg_loss, acc, macro_f1, all_labels, all_preds\n"
      ],
      "metadata": {
        "id": "tMv0OVT4ua1L"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFgeneHybridMLP(\n",
        "    tf_embed_cache=tf_embed_cache,\n",
        "    gene_embed_cache=gene_embed_cache,\n",
        "    tf_id_map=tf_id_map,\n",
        "    gene_id_map=gene_id_map,\n",
        "    hidden_dim=1024,\n",
        "    num_classes=3,\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "    test_loss, test_acc, test_f1, _, _ = eval_model(model, test_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk5Z7HpNudxp",
        "outputId": "0019922b-8890-40fa-9bc5-dbce028634ea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 1.0990, Train Acc: 0.3485 | Test Loss: 1.1003, Test Acc: 0.3144, Test F1: 0.1595\n",
            "Epoch 02 | Train Loss: 1.0973, Train Acc: 0.3528 | Test Loss: 1.0974, Test Acc: 0.3561, Test F1: 0.1751\n",
            "Epoch 03 | Train Loss: 1.0978, Train Acc: 0.3525 | Test Loss: 1.0964, Test Acc: 0.3561, Test F1: 0.1751\n",
            "Epoch 04 | Train Loss: 1.0961, Train Acc: 0.3596 | Test Loss: 1.0948, Test Acc: 0.3561, Test F1: 0.1751\n",
            "Epoch 05 | Train Loss: 1.0755, Train Acc: 0.3922 | Test Loss: 1.0491, Test Acc: 0.3910, Test F1: 0.2860\n",
            "Epoch 06 | Train Loss: 0.9767, Train Acc: 0.4814 | Test Loss: 0.8816, Test Acc: 0.5510, Test F1: 0.5288\n",
            "Epoch 07 | Train Loss: 0.8477, Train Acc: 0.5554 | Test Loss: 0.8809, Test Acc: 0.5497, Test F1: 0.5575\n",
            "Epoch 08 | Train Loss: 0.8248, Train Acc: 0.5782 | Test Loss: 0.7854, Test Acc: 0.6086, Test F1: 0.6102\n",
            "Epoch 09 | Train Loss: 0.7698, Train Acc: 0.6119 | Test Loss: 0.8774, Test Acc: 0.5690, Test F1: 0.5765\n",
            "Epoch 10 | Train Loss: 0.7290, Train Acc: 0.6358 | Test Loss: 0.7822, Test Acc: 0.6138, Test F1: 0.6043\n",
            "Epoch 11 | Train Loss: 0.7539, Train Acc: 0.6349 | Test Loss: 0.7255, Test Acc: 0.6546, Test F1: 0.6598\n",
            "Epoch 12 | Train Loss: 0.6841, Train Acc: 0.6708 | Test Loss: 0.8507, Test Acc: 0.5996, Test F1: 0.6094\n",
            "Epoch 13 | Train Loss: 0.6721, Train Acc: 0.6813 | Test Loss: 0.6939, Test Acc: 0.6611, Test F1: 0.6663\n",
            "Epoch 14 | Train Loss: 0.6804, Train Acc: 0.6787 | Test Loss: 0.6884, Test Acc: 0.6619, Test F1: 0.6636\n",
            "Epoch 15 | Train Loss: 0.6282, Train Acc: 0.7040 | Test Loss: 0.6778, Test Acc: 0.6791, Test F1: 0.6836\n",
            "Epoch 16 | Train Loss: 0.6344, Train Acc: 0.7069 | Test Loss: 0.6757, Test Acc: 0.6809, Test F1: 0.6828\n",
            "Epoch 17 | Train Loss: 0.6405, Train Acc: 0.6986 | Test Loss: 0.7622, Test Acc: 0.6452, Test F1: 0.6494\n",
            "Epoch 18 | Train Loss: 0.6367, Train Acc: 0.7048 | Test Loss: 0.7705, Test Acc: 0.6305, Test F1: 0.6173\n",
            "Epoch 19 | Train Loss: 0.6001, Train Acc: 0.7257 | Test Loss: 0.7749, Test Acc: 0.6232, Test F1: 0.6131\n",
            "Epoch 20 | Train Loss: 0.5896, Train Acc: 0.7315 | Test Loss: 0.7533, Test Acc: 0.6434, Test F1: 0.6261\n",
            "Epoch 21 | Train Loss: 0.6060, Train Acc: 0.7249 | Test Loss: 0.7028, Test Acc: 0.6744, Test F1: 0.6762\n",
            "Epoch 22 | Train Loss: 0.5673, Train Acc: 0.7459 | Test Loss: 0.8223, Test Acc: 0.6400, Test F1: 0.6434\n",
            "Epoch 23 | Train Loss: 0.5792, Train Acc: 0.7436 | Test Loss: 0.7596, Test Acc: 0.6529, Test F1: 0.6409\n",
            "Epoch 24 | Train Loss: 0.5724, Train Acc: 0.7510 | Test Loss: 0.9648, Test Acc: 0.5419, Test F1: 0.5222\n",
            "Epoch 25 | Train Loss: 0.5781, Train Acc: 0.7482 | Test Loss: 0.6708, Test Acc: 0.6972, Test F1: 0.6993\n",
            "Epoch 26 | Train Loss: 0.5582, Train Acc: 0.7535 | Test Loss: 0.6560, Test Acc: 0.7127, Test F1: 0.7197\n",
            "Epoch 27 | Train Loss: 0.5214, Train Acc: 0.7782 | Test Loss: 0.6252, Test Acc: 0.7226, Test F1: 0.7224\n",
            "Epoch 28 | Train Loss: 0.5142, Train Acc: 0.7792 | Test Loss: 0.6537, Test Acc: 0.7037, Test F1: 0.7038\n",
            "Epoch 29 | Train Loss: 0.5065, Train Acc: 0.7840 | Test Loss: 0.6813, Test Acc: 0.6989, Test F1: 0.7034\n",
            "Epoch 30 | Train Loss: 0.4957, Train Acc: 0.7917 | Test Loss: 0.6152, Test Acc: 0.7308, Test F1: 0.7302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc, test_f1, y_true, y_pred = eval_model(model, test_loader)\n",
        "\n",
        "print(\"Final Test Accuracy:\", test_acc)\n",
        "print(\"Final Test Macro F1:\", test_f1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVxQyaC2ufei",
        "outputId": "e9d36723-b255-46b6-b2a0-af7445b0eef7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.730752688172043\n",
            "Final Test Macro F1: 0.7302464646452856\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6681    0.8068    0.7309       766\n",
            "           1     0.8311    0.8618    0.8462       731\n",
            "           2     0.7025    0.5447    0.6136       828\n",
            "\n",
            "    accuracy                         0.7308      2325\n",
            "   macro avg     0.7339    0.7378    0.7302      2325\n",
            "weighted avg     0.7316    0.7308    0.7254      2325\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6wlxvqpujmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}