{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1HPfH13ZQ9cREr/60lAo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navidh86/perturbseq-10701/blob/master/Combine_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u73MkAaotApU",
        "outputId": "4291bf11-ee55-45b4-bf78-4ea40db80ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'perturbseq-10701'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 220 (delta 47), reused 53 (delta 17), pack-reused 121 (from 2)\u001b[K\n",
            "Receiving objects: 100% (220/220), 260.63 MiB | 16.64 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Updating files: 100% (57/57), done.\n",
            "/content/perturbseq-10701\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastparquet) (25.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n"
          ]
        }
      ],
      "source": [
        "# ONLY FOR COLAB\n",
        "!git clone https://github.com/navidh86/perturbseq-10701.git\n",
        "%cd ./perturbseq-10701\n",
        "!pip install fastparquet tqdm scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zIrLgcqtGSH",
        "outputId": "13a80bc8-b0f5-44aa-ea66-dbd30a80e6b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from data.reference_data_classification import (\n",
        "    PairPerturbSeqDataset,\n",
        "    perturbseq_collate_2,\n",
        "    get_dataloader,\n",
        ")\n",
        "\n",
        "train_loader = get_dataloader(\n",
        "    parquet_path=\"data/tf_gene_expression_labeled_v2.parquet\",\n",
        "    tf_sequences_path=\"data/tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"data/gene_sequences_4000bp.pkl\",\n",
        "    batch_size=128,\n",
        "    type=\"train\",\n",
        "    majority_fraction=0.005,\n",
        ")\n",
        "\n",
        "val_loader = get_dataloader(\n",
        "    parquet_path=\"data/tf_gene_expression_labeled_v2.parquet\",\n",
        "    tf_sequences_path=\"data/tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"data/gene_sequences_4000bp.pkl\",\n",
        "    batch_size=256,\n",
        "    type=\"val\",\n",
        "    majority_fraction=0.005,\n",
        ")\n",
        "\n",
        "test_loader = get_dataloader(\n",
        "    parquet_path=\"data/tf_gene_expression_labeled_v2.parquet\",\n",
        "    tf_sequences_path=\"data/tf_sequences.pkl\",\n",
        "    gene_sequences_path=\"data/gene_sequences_4000bp.pkl\",\n",
        "    batch_size=256,\n",
        "    type=\"test\",\n",
        "    majority_fraction=0.005,\n",
        ")\n",
        "\n",
        "print(\"Train batches:\", len(train_loader.dataset))\n",
        "print(\"Val batches:\", len(val_loader.dataset))\n",
        "print(\"Test batches:\", len(test_loader.dataset))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzYUjGv8tNC6",
        "outputId": "6cd91989-4ade-4369-a9b6-9feb8d45d0ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 10845\n",
            "Val batches: 2324\n",
            "Test batches: 2325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load NT sequence embeddings\n",
        "tf_embed_cache = pickle.load(open(\"./embeds/tf_cls.pkl\", \"rb\"))\n",
        "gene_embed_cache = pickle.load(open(\"./embeds/gn_cls.pkl\", \"rb\"))\n",
        "\n",
        "# ensure everything is torch tensors\n",
        "for k in tf_embed_cache:\n",
        "    if not isinstance(tf_embed_cache[k], torch.Tensor):\n",
        "        tf_embed_cache[k] = torch.tensor(tf_embed_cache[k], dtype=torch.float32)\n",
        "\n",
        "for k in gene_embed_cache:\n",
        "    if not isinstance(gene_embed_cache[k], torch.Tensor):\n",
        "        gene_embed_cache[k] = torch.tensor(gene_embed_cache[k], dtype=torch.float32)\n",
        "\n",
        "first_tf = next(iter(tf_embed_cache.values()))\n",
        "first_gene = next(iter(gene_embed_cache.values()))\n",
        "print(\"TF emb dim:\", first_tf.shape)\n",
        "print(\"Gene emb dim:\", first_gene.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbIFh874tVmi",
        "outputId": "946118cd-cf96-4b9b-f5f5-58eb3338a74f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF emb dim: torch.Size([1280])\n",
            "Gene emb dim: torch.Size([1280])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_loader.dataset\n",
        "val_ds = val_loader.dataset\n",
        "test_ds = test_loader.dataset\n",
        "\n",
        "# Use all TF/gene names across ALL splits\n",
        "combined_df = pd.concat([train_ds.df, val_ds.df, test_ds.df]).reset_index(drop=True)\n",
        "\n",
        "tf_names = sorted(combined_df[\"tf_name\"].unique().tolist())\n",
        "gene_names = sorted(combined_df[\"gene_name\"].unique().tolist())\n",
        "\n",
        "tf_id_map = {name: idx for idx, name in enumerate(tf_names)}\n",
        "gene_id_map = {name: idx for idx, name in enumerate(gene_names)}\n",
        "\n",
        "print(\"Num TF IDs:\", len(tf_id_map))\n",
        "print(\"Num Gene IDs:\", len(gene_id_map))\n",
        "\n",
        "# check if each TF/gene has an embedding\n",
        "missing_tf = [n for n in tf_names if n not in tf_embed_cache]\n",
        "missing_gene = [n for n in gene_names if n not in gene_embed_cache]\n",
        "print(\"Missing TF in cache:\", len(missing_tf))\n",
        "print(\"Missing gene in cache:\", len(missing_gene))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-8aBFMpuSuL",
        "outputId": "d299eb3e-a174-4a58-f135-cefbca377d15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num TF IDs: 223\n",
            "Num Gene IDs: 4539\n",
            "Missing TF in cache: 0\n",
            "Missing gene in cache: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(index, num_classes):\n",
        "    v = torch.zeros(num_classes, dtype=torch.float32)\n",
        "    v[index] = 1.0\n",
        "    return v\n"
      ],
      "metadata": {
        "id": "7ih5IJ4UxIO7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TFgeneHybridMLP(nn.Module):\n",
        "    def __init__(self, tf_embed_cache, gene_embed_cache, tf_id_map, gene_id_map,\n",
        "                 hidden_dim=1024, num_classes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tf_cache = tf_embed_cache\n",
        "        self.gene_cache = gene_embed_cache\n",
        "        self.tf_id_map = tf_id_map\n",
        "        self.gene_id_map = gene_id_map\n",
        "\n",
        "        self.num_tfs = len(tf_id_map)\n",
        "        self.num_genes = len(gene_id_map)\n",
        "\n",
        "        seq_dim = next(iter(tf_embed_cache.values())).shape[0]\n",
        "\n",
        "        # FINAL INPUT SIZE:\n",
        "        # TF_seq + Gene_seq + interaction + TF_onehot + Gene_onehot\n",
        "        in_dim = seq_dim*3 + self.num_tfs + self.num_genes\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(hidden_dim//2, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, batch_x):\n",
        "        X_list = []\n",
        "\n",
        "        for item in batch_x:\n",
        "            tf_name = item[\"tf_name\"]\n",
        "            gene_name = item[\"gene_name\"]\n",
        "\n",
        "            tf_seq = self.tf_cache[tf_name]\n",
        "            gene_seq = self.gene_cache[gene_name]\n",
        "            interaction = tf_seq * gene_seq\n",
        "\n",
        "            tf_onehot = torch.zeros(self.num_tfs)\n",
        "            gene_onehot = torch.zeros(self.num_genes)\n",
        "\n",
        "            tf_onehot[self.tf_id_map[tf_name]] = 1.0\n",
        "            gene_onehot[self.gene_id_map[gene_name]] = 1.0\n",
        "\n",
        "            vec = torch.cat([tf_seq, gene_seq, interaction, tf_onehot, gene_onehot])\n",
        "            X_list.append(vec)\n",
        "\n",
        "        X = torch.stack(X_list).to(device)\n",
        "        return self.net(X)\n"
      ],
      "metadata": {
        "id": "eNIK6aS1uYyD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        logits = model(batch_x)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        logits = model(batch_x)\n",
        "        loss = loss_fn(logits, batch_y)\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        total_loss += loss.item() * len(batch_y)\n",
        "        total_correct += (preds == batch_y).sum().item()\n",
        "        total_samples += len(batch_y)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    acc = total_correct / total_samples\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    return avg_loss, acc, macro_f1, all_labels, all_preds\n"
      ],
      "metadata": {
        "id": "tMv0OVT4ua1L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFgeneHybridMLP(\n",
        "    tf_embed_cache=tf_embed_cache,\n",
        "    gene_embed_cache=gene_embed_cache,\n",
        "    tf_id_map=tf_id_map,\n",
        "    gene_id_map=gene_id_map,\n",
        "    hidden_dim=1024,\n",
        "    num_classes=3,\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "best_val_f1 = -1\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer)\n",
        "\n",
        "    # validation\n",
        "    val_loss, val_acc, val_f1, _, _ = eval_model(model, val_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    # save best model\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        best_state = model.state_dict()\n",
        "        torch.save(best_state, \"best_hybrid_model.pt\")\n",
        "        print(f\"*** Saved best model at epoch {epoch} (Val F1={val_f1:.4f})\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk5Z7HpNudxp",
        "outputId": "9fe57c62-c78f-4bdf-fdbe-fd2bfc4af8a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 1.0992, Train Acc: 0.3526 | Val Loss: 1.0973, Val Acc: 0.3563, Val F1: 0.1751\n",
            "*** Saved best model at epoch 1 (Val F1=0.1751)\n",
            "Epoch 02 | Train Loss: 1.0976, Train Acc: 0.3546 | Val Loss: 1.0968, Val Acc: 0.3563, Val F1: 0.1751\n",
            "Epoch 03 | Train Loss: 1.0967, Train Acc: 0.3553 | Val Loss: 1.0956, Val Acc: 0.3563, Val F1: 0.1751\n",
            "Epoch 04 | Train Loss: 1.0964, Train Acc: 0.3511 | Val Loss: 1.0935, Val Acc: 0.3563, Val F1: 0.1751\n",
            "Epoch 05 | Train Loss: 1.0829, Train Acc: 0.3848 | Val Loss: 1.1146, Val Acc: 0.3141, Val F1: 0.1594\n",
            "Epoch 06 | Train Loss: 1.0263, Train Acc: 0.4444 | Val Loss: 0.9666, Val Acc: 0.4888, Val F1: 0.4483\n",
            "*** Saved best model at epoch 6 (Val F1=0.4483)\n",
            "Epoch 07 | Train Loss: 0.9025, Train Acc: 0.5317 | Val Loss: 1.1735, Val Acc: 0.4127, Val F1: 0.3336\n",
            "Epoch 08 | Train Loss: 0.8469, Train Acc: 0.5599 | Val Loss: 0.7937, Val Acc: 0.5899, Val F1: 0.5918\n",
            "*** Saved best model at epoch 8 (Val F1=0.5918)\n",
            "Epoch 09 | Train Loss: 0.7714, Train Acc: 0.6048 | Val Loss: 0.9436, Val Acc: 0.5280, Val F1: 0.4934\n",
            "Epoch 10 | Train Loss: 0.7610, Train Acc: 0.6134 | Val Loss: 0.7557, Val Acc: 0.6033, Val F1: 0.5953\n",
            "*** Saved best model at epoch 10 (Val F1=0.5953)\n",
            "Epoch 11 | Train Loss: 0.7127, Train Acc: 0.6367 | Val Loss: 0.7525, Val Acc: 0.6093, Val F1: 0.6014\n",
            "*** Saved best model at epoch 11 (Val F1=0.6014)\n",
            "Epoch 12 | Train Loss: 0.6945, Train Acc: 0.6524 | Val Loss: 0.7119, Val Acc: 0.6338, Val F1: 0.6402\n",
            "*** Saved best model at epoch 12 (Val F1=0.6402)\n",
            "Epoch 13 | Train Loss: 0.6827, Train Acc: 0.6643 | Val Loss: 0.7056, Val Acc: 0.6446, Val F1: 0.6484\n",
            "*** Saved best model at epoch 13 (Val F1=0.6484)\n",
            "Epoch 14 | Train Loss: 0.6521, Train Acc: 0.6807 | Val Loss: 0.7345, Val Acc: 0.6373, Val F1: 0.6322\n",
            "Epoch 15 | Train Loss: 0.6645, Train Acc: 0.6760 | Val Loss: 0.8794, Val Acc: 0.5568, Val F1: 0.5469\n",
            "Epoch 16 | Train Loss: 0.6404, Train Acc: 0.6985 | Val Loss: 0.6691, Val Acc: 0.6657, Val F1: 0.6721\n",
            "*** Saved best model at epoch 16 (Val F1=0.6721)\n",
            "Epoch 17 | Train Loss: 0.6304, Train Acc: 0.6982 | Val Loss: 0.7677, Val Acc: 0.6278, Val F1: 0.6273\n",
            "Epoch 18 | Train Loss: 0.6116, Train Acc: 0.7164 | Val Loss: 0.7235, Val Acc: 0.6429, Val F1: 0.6355\n",
            "Epoch 19 | Train Loss: 0.6271, Train Acc: 0.7041 | Val Loss: 0.6713, Val Acc: 0.6773, Val F1: 0.6696\n",
            "Epoch 20 | Train Loss: 0.5995, Train Acc: 0.7262 | Val Loss: 0.6481, Val Acc: 0.6829, Val F1: 0.6836\n",
            "*** Saved best model at epoch 20 (Val F1=0.6836)\n",
            "Epoch 21 | Train Loss: 0.5720, Train Acc: 0.7398 | Val Loss: 0.6911, Val Acc: 0.6734, Val F1: 0.6645\n",
            "Epoch 22 | Train Loss: 0.5422, Train Acc: 0.7560 | Val Loss: 0.7171, Val Acc: 0.6730, Val F1: 0.6670\n",
            "Epoch 23 | Train Loss: 0.5575, Train Acc: 0.7500 | Val Loss: 0.8147, Val Acc: 0.6532, Val F1: 0.6376\n",
            "Epoch 24 | Train Loss: 0.5593, Train Acc: 0.7506 | Val Loss: 0.6482, Val Acc: 0.6971, Val F1: 0.7022\n",
            "*** Saved best model at epoch 24 (Val F1=0.7022)\n",
            "Epoch 25 | Train Loss: 0.5070, Train Acc: 0.7821 | Val Loss: 0.7434, Val Acc: 0.6657, Val F1: 0.6753\n",
            "Epoch 26 | Train Loss: 0.4916, Train Acc: 0.7899 | Val Loss: 0.8719, Val Acc: 0.6097, Val F1: 0.6069\n",
            "Epoch 27 | Train Loss: 0.5006, Train Acc: 0.7829 | Val Loss: 0.6361, Val Acc: 0.7151, Val F1: 0.7104\n",
            "*** Saved best model at epoch 27 (Val F1=0.7104)\n",
            "Epoch 28 | Train Loss: 0.5082, Train Acc: 0.7792 | Val Loss: 0.6316, Val Acc: 0.7134, Val F1: 0.7134\n",
            "*** Saved best model at epoch 28 (Val F1=0.7134)\n",
            "Epoch 29 | Train Loss: 0.4699, Train Acc: 0.8051 | Val Loss: 0.7574, Val Acc: 0.6829, Val F1: 0.6746\n",
            "Epoch 30 | Train Loss: 0.4852, Train Acc: 0.7928 | Val Loss: 0.6662, Val Acc: 0.6945, Val F1: 0.6752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load(\"best_hybrid_model.pt\"))\n",
        "\n",
        "test_loss, test_acc, test_f1, y_true, y_pred = eval_model(model, test_loader)\n",
        "\n",
        "print(\"\\n=== FINAL TEST RESULTS ===\")\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"Test Macro F1:\", test_f1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVxQyaC2ufei",
        "outputId": "2ace7aca-b180-4703-a9e5-d61b4700eb22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FINAL TEST RESULTS ===\n",
            "Test Loss: 0.6436375150372905\n",
            "Test Accuracy: 0.7255913978494624\n",
            "Test Macro F1: 0.7257591843778003\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7644    0.6227    0.6863       766\n",
            "           1     0.7849    0.9083    0.8421       731\n",
            "           2     0.6386    0.6594    0.6488       828\n",
            "\n",
            "    accuracy                         0.7256      2325\n",
            "   macro avg     0.7293    0.7302    0.7258      2325\n",
            "weighted avg     0.7260    0.7256    0.7220      2325\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6wlxvqpujmS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}